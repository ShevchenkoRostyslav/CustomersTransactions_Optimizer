{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home assignment from Wirecard.\n",
    "# received 16.01 \n",
    "# Notebook for Task 3 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 and 4\n",
    "\n",
    "The aim of this assignment is to fit a model to the data, so that predictions about the customers’ purchase behavior in future can be made. The model is defined by four parameters namely r, α, a, b and they are always greater than 0. For fitting the model (i.e. finding the parameters r, α, a, b), Maximum Likelihood Estimation (MLE) can be used. The log likelihood (LL) function which is to be maximized is given as follows:\n",
    "\n",
    "![title](img/NLL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the objective function given by Eq. 2 as an optimizable (minimizable) function. Note that the natural logarithm of the Gamma function is already available in different programming languages, so this can be used directly. Details about the function are:\n",
    "\n",
    "* Input parameters: x, tx, T for all customers\n",
    "* Model parameters: r, α, a, b\n",
    "* Output parameter: The value of the function (NLL i.e. Eq. 2) evaluated at some value of r, α, a, b given the customers' data x, tx and T.\n",
    "\n",
    "Minimize this function using a numerical method for non-linear optimization problems e.g. the Nelder-Mead algorithm (which does not require calculation of derivatives). Alternately, other algorithms e.g. L-BFGS can be used, gradient calculations can be performed using numerical approximations.\n",
    "\n",
    "The starting point for parameters r, α, a, b can be taken as the result of evaluating Gaussian functions with mean 1.0 and standard deviation 0.05. Also, these four parameters are always greater than 0, so in case during optimization, if any of these parameters tend to go towards negative, this can be handled for example by returning infinity as the output parameter of the objective function.\n",
    "\n",
    "The parameters tx and T have to be normalized before passing them to the function. For this, do the following:\n",
    "- Get the maximum value of T from the available values\n",
    "- Calculate the normalization factor by dividing 10.0 by the maximum value of T\n",
    "- Multiply every element in tx and T vector by this factor\n",
    "\n",
    "Also, the model parameter α has the same units like tx and T, so it also has to be multiplied by the normalization factor inside the objective function before any evaluations. To summarize, while calculating Eq. 2, use scaled α, tx and T values.\n",
    "\n",
    "Find the optimal values of r, α, a, b that minimize the objective function and define a strategy to check convergence from different starting points. Save these parameter estimates in a csv file called estimated_parameters.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "# treatment of the warnings\n",
    "import warnings\n",
    "# ln of the Gamma function \n",
    "from scipy.special import gammaln as lnG\n",
    "# for minimization\n",
    "from scipy import optimize\n",
    "# write the final parameters\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>x</th>\n",
       "      <th>tx</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30.43</td>\n",
       "      <td>38.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.71</td>\n",
       "      <td>38.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer ID  x     tx      T\n",
       "0            1  2  30.43  38.86\n",
       "1            2  1   1.71  38.86\n",
       "2            3  0   0.00  38.86\n",
       "3            4  0   0.00  38.86\n",
       "4            5  0   0.00  38.86"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the .csv file\n",
    "df = pd.read_csv('csv/summary_customers.csv',index_col='Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomFunction class\n",
    "\n",
    "Implementation of a custom optimizable (minimizable) function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFunction:\n",
    "    def __init__(self, verbose=False):\n",
    "        \"\"\"Constructor + initialization of the fit parameters\"\"\"\n",
    "        self.verbose = verbose\n",
    "        #initialize model parameters\n",
    "        self.__initialize_par()\n",
    "        \n",
    "    def __obj_f(self, params, df):\n",
    "        \"\"\"Implementation of the objective function.\n",
    "        \n",
    "        NLL = -1/N Sum( lnA1i + lnA2i + ln( exp(lnA3i) + delta exp(lnA4i)) )\n",
    "        \"\"\"\n",
    "        #update parameters\n",
    "        self.__update_params(params)\n",
    "        \n",
    "        #normalise alpha\n",
    "        alpha_norm =self.alpha * self.norm\n",
    "        # protection from negative parameters\n",
    "        if self.r <=0 or self.b <=0 or self.a <= 0 or alpha_norm <= 0:\n",
    "            return np.inf\n",
    "        # number os samples\n",
    "        N = len(df)\n",
    "        # loss function\n",
    "        with warnings.catch_warnings():\n",
    "            # catch warnings from \"bad\" values in the log. \n",
    "            # they are treated with the corresponding value of the NLL\n",
    "            warnings.simplefilter(\"ignore\",RuntimeWarning)\n",
    "            obj_i = self.__loss(df,self.r,alpha_norm,self.a,self.b)\n",
    "        # protection from the inf values that might arise from division by zero\n",
    "        if obj_i.isin([np.inf]).values.any():\n",
    "            return np.inf\n",
    "        # normalised NLL\n",
    "        out = obj_i.sum() * (-1) / N\n",
    "        return out\n",
    "    \n",
    "    def __loss(self, df,r,alpha,a,b):\n",
    "        \"\"\"Implementation of the loss function.\n",
    "        \"\"\"\n",
    "        lnA1 = lnG(r+df.x) + r*np.log(alpha) - lnG(r)\n",
    "        lnA2 = lnG(a+b) + lnG(b+df.x) - lnG(b) - lnG(a+b+df.x)\n",
    "        lnA3 = -(r+df.x)*np.log(alpha+df['T'])\n",
    "        lnA4 = np.log(a) - np.log(b+df.x-1) - (r+df.x)*np.log(alpha + df.tx)\n",
    "        deltaA4 = self.__deltaA4(df.x,np.exp(lnA4))\n",
    "        out = lnA1 + lnA2 + np.log(np.exp(lnA3) + deltaA4)\n",
    "        return out\n",
    "    \n",
    "    def __deltaA4(self,x,A4):\n",
    "        \"\"\"Implementation of the delta function.\n",
    "        deltaX = 0 if x <= 0 \n",
    "        deltaX = X otherwise\n",
    "        \"\"\"\n",
    "        A4[x <= 0] = 0\n",
    "        return A4\n",
    "    \n",
    "    def __update_params(self, new_params):\n",
    "        \"\"\"Update model parameters\n",
    "        \"\"\"\n",
    "        self.r = new_params[0].copy()\n",
    "        self.alpha = new_params[1].copy()\n",
    "        self.a = new_params[2].copy()\n",
    "        self.b = new_params[3].copy()\n",
    "    \n",
    "    def __initialize_par(self):\n",
    "        \"\"\"Method to initialize parameters with Gaus(1,0.05)\n",
    "        \"\"\"\n",
    "        self.r, self.alpha, self.a, self.b = np.random.normal(1, 0.05,4)\n",
    "    \n",
    "    def set_r(self, r):\n",
    "        \"\"\"Method to set parameter r\n",
    "        \"\"\"        \n",
    "        if r <= 0: \n",
    "            raise ValueError('r should be positive')\n",
    "        self.r = r\n",
    "        \n",
    "    def set_alpha(self, alpha):\n",
    "        \"\"\"Method to set parameter alpha\n",
    "        \"\"\"\n",
    "        if alpha <= 0: \n",
    "            raise ValueError('alpha should be positive')\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def set_a(self, a):\n",
    "        \"\"\"Method to set parameter a\n",
    "        \"\"\"        \n",
    "        if a <= 0: \n",
    "            raise ValueError('a should be positive')\n",
    "        self.a = a\n",
    "        \n",
    "    def set_b(self, b):\n",
    "        \"\"\"Method to set parameter b\n",
    "        \"\"\"\n",
    "        if b <= 0: \n",
    "            raise ValueError('b should be positive')\n",
    "        self.b = b\n",
    "    \n",
    "    def set_parameters(self, r, alpha, a, b):\n",
    "        \"\"\"Method to set the fit parameters\n",
    "        \"\"\"\n",
    "        self.set_r(r), self.set_alpha(alpha), self.set_a(a), self.set_b(b)\n",
    "    \n",
    "    def fit(self, df, minimizer_strategy = [(2,'Nelder-Mead')]):\n",
    "        \"\"\"Implementation of the custom minimisation procedure.\n",
    "        \n",
    "        Parameters:\n",
    "        df - pandas DataFrame with the input data of the next format (x,tx,T),\n",
    "        minimizer_strategy - list of pears specifying the minimzersand number of calls to be used\n",
    "        (default [(2,'Nelder-Mead')])\n",
    "        \"\"\"\n",
    "        # check the input data\n",
    "        self.__validate_df(df)\n",
    "        # compute the scalefactor and normalise the data\n",
    "        norm_df = self.__normalise_data(df)\n",
    "        # initial parameters\n",
    "        initial_pars = [self.r,self.alpha,self.a,self.b]\n",
    "    \n",
    "        for num_iter,minimizer in minimizer_strategy:\n",
    "            print('Run {} minimizer'.format(minimizer))\n",
    "            for i in range(1,num_iter+1):\n",
    "                print('Step ',i)\n",
    "                initial_pars = [self.r,self.alpha,self.a,self.b]\n",
    "                if self.verbose: print('Initialisation: r = ',self.r, ' alpha = ',self.alpha, ' a = ',self.a, ' b = ',self.b)\n",
    "                # perform the minimization\n",
    "                self.fit_res = sp.optimize.minimize(self.__obj_f,x0 = initial_pars,args=(norm_df), method=minimizer) \n",
    "                # update the model parameters\n",
    "                self.__update_params(self.fit_res.x)\n",
    "                if i!= num_iter+1 and self.verbose:\n",
    "                    self.print_final_results()\n",
    "                    print('\\n')\n",
    "                \n",
    "    def fit_global(self, df, minimizer_strategy = 'Nelder-Mead',num_iter = 100):\n",
    "        \"\"\"Implementation of the global (brut-force) minima finding algorithm - basinhopping\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.basinhopping.html#scipy.optimize.basinhopping\n",
    "        Large number of iterations is recommended due to a step-based optimisation procedure.\n",
    "        Fit succeed if 15% of num_iter the global minimum candidate remains the same.\n",
    "        \n",
    "        Parameters:\n",
    "        df - pandas DataFrame with the input data of the next format (x,tx,T),\n",
    "        minimizer_strategy - The minimization method (default: Nelder-Mead),\n",
    "        num_iter - number of max iterations (default: 100)\n",
    "        \"\"\"\n",
    "        # check the input data\n",
    "        self.__validate_df(df)\n",
    "        # compute the scalefactor and normalise the data\n",
    "        norm_df = self.__normalise_data(df)\n",
    "        # initial parameters\n",
    "        initial_pars = [self.r,self.alpha,self.a,self.b]\n",
    "        print('********Basin-hopping minimisation********')\n",
    "        if self.verbose: print('Initialisation: r = ',self.r, ' alpha = ',self.alpha, ' a = ',self.a, ' b = ',self.b)\n",
    "        # perform the minimisation\n",
    "        self.fit_res = sp.optimize.basinhopping(self.__obj_f,x0 = initial_pars, \n",
    "                                            minimizer_kwargs={\"method\": minimizer_strategy,'args':(norm_df)},\n",
    "                                            stepsize = 0.05,\n",
    "                                            niter = num_iter,\n",
    "                                            niter_success = int(num_iter*0.15),\n",
    "                                            disp = self.verbose)\n",
    "        # update the model parameters\n",
    "        self.__update_params(self.fit_res.x)\n",
    "    \n",
    "    def __validate_df(self,df):\n",
    "        \"\"\"Method to check whether the input DataFrame contains\n",
    "        required Series (x,xt,T) and free of NaNs\"\"\"\n",
    "        cols = ['x','tx','T']\n",
    "        for c in cols:\n",
    "            if c not in df.columns:\n",
    "                raise ValueError('Column ' + c + ' is missing in the input DataFrame.')\n",
    "    \n",
    "    def __normalise_data(self,df):\n",
    "        \"\"\"Method to normalise parameters tx and T\n",
    "        \"\"\"\n",
    "        df_temp = df.copy()\n",
    "        self.__norm_sf(df)\n",
    "        df_temp['tx']*=self.norm\n",
    "        df_temp['T']*=self.norm\n",
    "        return df_temp\n",
    "    \n",
    "    def __norm_sf(self,df):\n",
    "        \"\"\"Method to compute the normalisation factor\n",
    "        \"\"\"\n",
    "        max_T = df['T'].max()\n",
    "        self.norm = 10./ max_T\n",
    "    \n",
    "    def print_final_results(self):\n",
    "        \"\"\"Method to print final results\n",
    "        \"\"\"\n",
    "        print('*********Minimisation is done*********')\n",
    "        # For some minimzers success and status are not defined\n",
    "        # e.g. doesn't work for basinhopping\n",
    "        try:\n",
    "            print('Success: ',self.fit_res.success)\n",
    "            print('Status: ',self.fit_res.status)\n",
    "        except Exception: pass\n",
    "        print('NLL: ',self.fit_res.fun)\n",
    "        print('Optimized parameters: r = ',self.r, ' alpha = ',self.alpha, ' a = ',self.a, ' b = ',self.b)\n",
    "        if self.verbose:\n",
    "            print(self.fit_res)\n",
    "            \n",
    "    def getFitResults(self):\n",
    "        \"\"\"Method to return the fit results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.fit_res\n",
    "        except Exception:\n",
    "            print('Fit has not been applied yet, no fit result object exist.')\n",
    "            return None\n",
    "    \n",
    "    def getFitParameters(self,digits = 0):\n",
    "        \"\"\"Method to return the fit parameters\n",
    "        \"\"\"\n",
    "        if digits != 0:\n",
    "            return (round(x,digits) for x in self.getFitParameters())\n",
    "        return self.r, self.alpha, self.a, self.b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Nelder-Mead minimizer\n",
      "Step  1\n",
      "Step  2\n",
      "*********Minimisation is done*********\n",
      "Success:  True\n",
      "Status:  0\n",
      "NLL:  2.6505481706776455\n",
      "Optimized parameters: r =  0.24259123935904925  alpha =  4.413484054346327  a =  0.7928829005072499  b =  2.425763897154502\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tyhe class object\n",
    "model = CustomFunction(verbose=False)\n",
    "# Fit with the custom minimization routine\n",
    "model.fit(df,minimizer_strategy=[(2,'Nelder-Mead')])\n",
    "# Fit with the global minimizer \n",
    "#model.fit_global(df,minimizer_strategy='Nelder-Mead',num_iter=300)\n",
    "model.print_final_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write final parameters to the .csv file\n",
    "with open('csv/estimated_parameters.csv','w') as file:\n",
    "    writer = csv.writer(file,delimiter=',',)\n",
    "    writer.writerow(['r','alpha','a','b'])\n",
    "    writer.writerow(model.getFitParameters(2)) # rounded to 2 digits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
